{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "import io\n",
    "from matplotlib import colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first load the dataset and figure out how big it is...\n",
    "datasetFileName = 'ralpn_a.tfrecords'\n",
    "dataset = tf.data.TFRecordDataset(datasetFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of examples in this dataset\n",
    "numExamples = sum([1 for i in dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: {class: (), image: ()}, types: {class: tf.string, image: tf.string}>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the dataset is just a bunch of serialized images and classification masks ('labels')\n",
    "# we need to convert data back into images and make an actual dataset to be fed into the CNN\n",
    "# mostly from: https://docs.microsoft.com/en-us/azure/databricks/_static/notebooks/deep-learning/mnist-tfrecords-to-tensorflow.html\n",
    "# this is directly from the Kaggle notebook\n",
    "def _bytes_feature(value):\n",
    "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "  if isinstance(value, type(tf.constant(0))):\n",
    "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "# Create a dictionary describing the features.\n",
    "image_feature_description = {\n",
    "    'image': tf.io.FixedLenFeature([], tf.string),\n",
    "    'class': tf.io.FixedLenFeature([], tf.string)\n",
    "}\n",
    "\n",
    "def _parse_image_function(example_proto):\n",
    "  # Parse the input tf.Example proto using the dictionary above.\n",
    "  return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "\n",
    "parsed_dataset = dataset.map(_parse_image_function)\n",
    "view_dataset = parsed_dataset # so we don't use up the iterator\n",
    "parsed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mask_to_image(image_arr,mask_arr):\n",
    "    mask_colors = np.array([[0, 0, 0], [255,191,0], [0,255,0], [255,84,84], [84,84,255]])/255.0\n",
    "    image_hsv_arr = colors.rgb_to_hsv(image_arr.astype(np.float)/255.0)\n",
    "    mask_slice = mask_arr[:,:,0]\n",
    "    \n",
    "    for labelIdx in range(5):\n",
    "        \n",
    "        # get label_mask\n",
    "        label_mask = (mask_slice == labelIdx)\n",
    "        #print(label_mask)\n",
    "        \n",
    "        # get color\n",
    "        this_color_hsv = colors.rgb_to_hsv(mask_colors[labelIdx,:])\n",
    "        \n",
    "        # update hue\n",
    "        image_hsv_arr[:,:,0] = image_hsv_arr[:,:,0] + np.multiply(this_color_hsv[0], label_mask)\n",
    "        \n",
    "        # update saturation\n",
    "        image_hsv_arr[:,:,1] = image_hsv_arr[:,:,1] + np.multiply(this_color_hsv[1], label_mask)\n",
    "    \n",
    "    new_image =  colors.hsv_to_rgb(image_hsv_arr)*255.0\n",
    "        \n",
    "    return new_image.astype(np.uint8)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'label2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-2bbcc0177572>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m#label2 = Image.open(io.BytesIO(label))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mlabel_arr_raw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[1;31m#label_arr = np.multiply(label_arr_raw.astype(float), (255.0/4.0) ).astype(np.uint8)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m#display.display(Image.fromarray(label_arr))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'label2' is not defined"
     ]
    }
   ],
   "source": [
    "# look at an example image\n",
    "for image_features in view_dataset.take(1):\n",
    "    image = image_features['image'].numpy()\n",
    "    #display.display(display.Image(data=image))\n",
    "    label = image_features['class'].numpy()\n",
    "    #display.display(display.Image(data=label))\n",
    "    \n",
    "    image2 = Image.open(io.BytesIO(image))\n",
    "    image_arr = np.asarray(image2)\n",
    "    #print(image_arr.shape)\n",
    "    #display.display(Image.fromarray(image_arr))   #### EASIEST WAY TO DISPLAY AN IMAGE FROM A NUMPY ARRAY!!! #########\n",
    "\n",
    "    label2 = Image.open(io.BytesIO(label))\n",
    "    label_arr_raw = np.asarray(label2)\n",
    "    #label_arr = np.multiply(label_arr_raw.astype(float), (255.0/4.0) ).astype(np.uint8)\n",
    "    #display.display(Image.fromarray(label_arr))\n",
    "    \n",
    "    image_masked_arr = apply_mask_to_image(image_arr,label_arr_raw)\n",
    "    display.display(Image.fromarray(image_masked_arr))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# https://stackoverflow.com/questions/51125266/how-do-i-split-tensorflow-datasets\n",
    "#train_size = int(0.7 * DATASET_SIZE)\n",
    "#val_size = int(0.15 * DATASET_SIZE)\n",
    "#test_size = int(0.15 * DATASET_SIZE)\n",
    "\n",
    "#full_dataset = tf.data.TFRecordDataset(FLAGS.input_file)\n",
    "#full_dataset = full_dataset.shuffle()\n",
    "#train_dataset = full_dataset.take(train_size)\n",
    "#test_dataset = full_dataset.skip(train_size)\n",
    "#val_dataset = test_dataset.skip(test_size)\n",
    "#test_dataset = test_dataset.take(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try a bunch of stuff\n",
    "myarr = np.array([[1,2],[3,4]])\n",
    "print(myarr == 2)\n",
    "myarr2 = np.multiply(myarr,(myarr==2))\n",
    "print(myarr2)\n",
    "\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "    \n",
    "    \n",
    "myarr3d = np.array([ [[1,1],[1,1]], [[2,2],[2,2]], [[3,3],[3,3]] ])\n",
    "print(myarr3d)\n",
    "print(myarr3d.shape)\n",
    "myarr3d_slice = myarr3d[0,:,:]\n",
    "\n",
    "print(myarr3d_slice)\n",
    "\n",
    "mycolors = np.array([[0, 0, 0], [255,191,255], [0,255,0], [255,84,84], [84,84,255]])\n",
    "print(mycolors[1,:])\n",
    "print(colors.rgb_to_hsv(mycolors[1,:]))\n",
    "\n",
    "myarr2d = myarr3d[0,:,:] + myarr3d[1,:,:]\n",
    "print(myarr2d)\n",
    "\n",
    "np.ones((4,4))\n",
    "np.ones(myarr2d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myarr2d = np.array([[1,2],[3,4]])\n",
    "print(myarr2d)\n",
    "myarr2d[0,:] = myarr2d[0,:] + np.ones(myarr2d[0,:].shape)\n",
    "print(myarr2d)\n",
    "\n",
    "red = np.array([255,0,0])\n",
    "print(red)\n",
    "red_hsv = colors.rgb_to_hsv(red/255.0)\n",
    "print(red_hsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display.display(Image.fromarray(image_arr))\n",
    "#np.amax(image_arr)\n",
    "image_arr_hsv = colors.rgb_to_hsv(image_arr.astype(np.float)/255.0)\n",
    "image_arr_hsv[:,:,1] =  image_arr_hsv[:,:,1] + np.ones(image_arr_hsv[:,:,1].shape)\n",
    "image_arr_red = colors.hsv_to_rgb(image_arr_hsv)\n",
    "image_arr_red_uint8 = (image_arr_red*255.0).astype(np.uint8)\n",
    "display.display(Image.fromarray(image_arr_red_uint8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
